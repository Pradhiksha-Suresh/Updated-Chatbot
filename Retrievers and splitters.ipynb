{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42e159-a23a-4c06-9fea-08d1279a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, DocArrayInMemorySearch\n",
    "from langchain.retrievers import BM25Retriever  \n",
    "from langchain.retrievers.ensemble import EnsembleRetriever\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "# Load the PDF document\n",
    "loader = PyPDFLoader(\"/Users/pradhikshasuresh/Documents/Python/Space.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#initiating chunking\n",
    "text_splitter_character = CharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "text_splitter_recursive = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "text_splitter_token = TokenTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "text_splitter_semantic = SemanticChunker(OpenAIEmbeddings(openai_api_key='MY OPEN_API_KEY'))                                             \n",
    "\n",
    "#splitting document\n",
    "docs_character = text_splitter_character.split_documents(documents)\n",
    "docs_recursive = text_splitter_recursive.split_documents(documents)\n",
    "docs_token = text_splitter_token.split_documents(documents)\n",
    "docs_semantic = text_splitter_semantic.split_documents(documents)\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key='MY OPEN_API_KEY')\n",
    "\n",
    "# Create a vector store with Chroma\n",
    "db_character = Chroma.from_documents(docs_character, embeddings)\n",
    "db_recursive = Chroma.from_documents(docs_recursive, embeddings)\n",
    "db_token = Chroma.from_documents(docs_token, embeddings)\n",
    "db_semantic = Chroma.from_documents(docs_semantic, embeddings)\n",
    "\n",
    "# Initialize the LLM model\n",
    "llm_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key='MY OPEN_API_KEY')\n",
    "\n",
    "#Combination1 - Similarity retriever with character chunking\n",
    "# Create a similarity retriever\n",
    "retriever_similarity1 = db_character.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "# Create QA chain \n",
    "qa_1 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_similarity1\n",
    ")\n",
    "\n",
    "#Combination2 - Similarity retriever with recursive chunking\n",
    "# Create a similarity retriever\n",
    "retriever_similarity2 = db_recursive.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "# Create QA chain \n",
    "qa_2 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_similarity2\n",
    ")\n",
    "\n",
    "#Combination3 - Similarity retriever with token chunking\n",
    "# Create a similarity retriever\n",
    "retriever_similarity3 = db_token.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "# Create QA chain \n",
    "qa_3 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_similarity3\n",
    ")\n",
    "\n",
    "#Combination4 - Similarity retriever with semantic chunking\n",
    "# Create a similarity retriever\n",
    "retriever_similarity4 = db_semantic.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "# Create QA chain \n",
    "qa_4 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_similarity4,\n",
    ")\n",
    "\n",
    "#Combination5 - BM25 retriever with Character chunking\n",
    "# Create a BM25 retriever\n",
    "retriever_bm251 = BM25Retriever.from_documents(docs_character)\n",
    "# Create QA chain for BM25 retriever\n",
    "qa_5 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_bm251,\n",
    ")\n",
    "\n",
    "#Combination6 - BM25 retriever with Recursive chunking\n",
    "# Create a BM25 retriever\n",
    "retriever_bm252 = BM25Retriever.from_documents(docs_recursive)\n",
    "# Create QA chain for BM25 retriever\n",
    "qa_6 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_bm252,\n",
    ")\n",
    "\n",
    "#Combination7 - BM25 retriever with Token chunking\n",
    "# Create a BM25 retriever\n",
    "retriever_bm253 = BM25Retriever.from_documents(docs_token)\n",
    "# Create QA chain for BM25 retriever\n",
    "qa_7 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_bm253,\n",
    ")\n",
    "\n",
    "#Combination8 - BM25 retriever with Semantic chunking\n",
    "# Create a BM25 retriever\n",
    "retriever_bm254 = BM25Retriever.from_documents(docs_semantic)\n",
    "# Create QA chain for BM25 retriever\n",
    "qa_8 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_bm254,\n",
    ")\n",
    "\n",
    "#Combination9 - Ensemble retriever with Character chunking\n",
    "#Initialize the Ensemble Retriever with BM25 and similarity retrievers\n",
    "ensemble_retriever1 = EnsembleRetriever(retrievers=[retriever_similarity1, retriever_bm251])\n",
    "# Create QA chain for ensemble retriever\n",
    "qa_9 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=ensemble_retriever1,\n",
    "    chain_type=\"stuff\",\n",
    ")\n",
    "\n",
    "#Combination10 - Ensemble retriever with Recursive chunking\n",
    "#Initialize the Ensemble Retriever with BM25 and similarity retrievers\n",
    "ensemble_retriever2 = EnsembleRetriever(retrievers=[retriever_similarity2, retriever_bm252])\n",
    "# Create QA chain for ensemble retriever\n",
    "qa_10 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=ensemble_retriever2,\n",
    "    chain_type=\"stuff\",\n",
    ")\n",
    "\n",
    "#Combination11 - Ensemble retriever with Recursive chunking\n",
    "#Initialize the Ensemble Retriever with BM25 and similarity retrievers\n",
    "ensemble_retriever3 = EnsembleRetriever(retrievers=[retriever_similarity3, retriever_bm253])\n",
    "# Create QA chain for ensemble retriever\n",
    "qa_11 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=ensemble_retriever3,\n",
    "    chain_type=\"stuff\",\n",
    ")\n",
    "\n",
    "#Combination12 - Ensemble retriever with Recursive chunking\n",
    "#Initialize the Ensemble Retriever with BM25 and similarity retrievers\n",
    "ensemble_retriever4 = EnsembleRetriever(retrievers=[retriever_similarity4, retriever_bm254])\n",
    "# Create QA chain for ensemble retriever\n",
    "qa_12 = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_model,\n",
    "    retriever=ensemble_retriever4,\n",
    "    chain_type=\"stuff\",\n",
    ")\n",
    "\n",
    "chat_history=[]\n",
    "question1=\"Explain the concept of vacuum\"\n",
    "question2=\"Briefly explain what are charged particles and their 3 primary sources\"\n",
    "question3=\"What is freefall?\"\n",
    "\n",
    "# Define combinations and their respective QA objects\n",
    "combinations = [\n",
    "    (qa_1, \"Combination 1\"), (qa_2, \"Combination 2\"), (qa_3, \"Combination 3\"),\n",
    "    (qa_4, \"Combination 4\"), (qa_5, \"Combination 5\"), (qa_6, \"Combination 6\"),\n",
    "    (qa_7, \"Combination 7\"), (qa_8, \"Combination 8\"), (qa_9, \"Combination 9\"),\n",
    "    (qa_10, \"Combination 10\"), (qa_11, \"Combination 11\"), (qa_12, \"Combination 12\")\n",
    "]\n",
    "\n",
    "# Define questions\n",
    "questions = [question1, question2, question3]\n",
    "\n",
    "# Initialize results storage\n",
    "results = {}\n",
    "\n",
    "# Iterate over combinations\n",
    "for qa, combination_name in combinations:\n",
    "    results[f\"Results for {combination_name}\"] = []\n",
    "    for question in questions:\n",
    "        results[f\"Results for {combination_name}\"].append(qa.invoke({\"question\": question, \"chat_history\": chat_history}))\n",
    "\n",
    "# Example of accessing results\n",
    "for combination, result_list in results.items():\n",
    "    print(combination)\n",
    "    for idx, result in enumerate(result_list):\n",
    "        print(f\"Question {idx + 1}: {result}\")\n",
    "        # Print a blank line after each answer\n",
    "        print()  # This prints a newline\n",
    "    print() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b2e61-fcb5-4f21-85d3-dee048354f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

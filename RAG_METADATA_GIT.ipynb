{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b60f6-d7eb-4a19-974c-ce42945e9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METADATA ENRICHMENT TO RAG PIPELINE\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "import panel as pn\n",
    "import param\n",
    "import pandas as pd\n",
    "import os\n",
    "import fitz  # PyMuPDF for PDF handling\n",
    "from langdetect import detect  # Library for language detection\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index.core import Document\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.extractors import (\n",
    "    TitleExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    SummaryExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = 'MY_API_KEY'\n",
    "\n",
    "# Helper function to normalize metadata values\n",
    "def normalize_metadata(metadata):\n",
    "    normalized_metadata = {}\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, list):\n",
    "            # Convert lists to strings or other appropriate types\n",
    "            normalized_metadata[key] = ', '.join(map(str, value))\n",
    "        elif isinstance(value, (str, int, float, bool)):\n",
    "            # Keep other types unchanged\n",
    "            normalized_metadata[key] = value\n",
    "        else:\n",
    "            # Handle unexpected types\n",
    "            normalized_metadata[key] = str(value)\n",
    "    return normalized_metadata\n",
    "\n",
    "# Define the helper function to load the database with metadata extraction\n",
    "def load_db(file, file_type, chain_type, k):\n",
    "    try:\n",
    "        # Load documents based on file type\n",
    "        if file_type == 'pdf':\n",
    "            loader = PyPDFLoader(file)\n",
    "            documents = loader.load()\n",
    "        elif file_type == 'csv':\n",
    "            loader = CSVLoader(file_path=file)\n",
    "            documents = loader.load()\n",
    "        elif file_type == 'docx':\n",
    "            loader = Docx2txtLoader(file)\n",
    "            documents = loader.load()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_type}\")\n",
    "\n",
    "        # Combine the text of the documents\n",
    "        combined_text = \" \".join([doc.page_content for doc in documents])\n",
    "\n",
    "        # Initialize LlamaIndex extractors\n",
    "        llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.2, api_key=api_key)\n",
    "        entity_extractor = EntityExtractor(\n",
    "            prediction_threshold=0.5,\n",
    "            label_entities=False,\n",
    "            device=\"cpu\",\n",
    "        )\n",
    "        qa_extractor = QuestionsAnsweredExtractor(questions=3, llm=llm)\n",
    "        summary_extractor = SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm)\n",
    "        title_extractor = TitleExtractor(nodes=5, llm=llm)\n",
    "        keyword_extractor = KeywordExtractor(keywords=10, llm=llm)\n",
    "        node_parser = SentenceSplitter()\n",
    "\n",
    "        transformations = [node_parser, title_extractor, entity_extractor, summary_extractor, qa_extractor, keyword_extractor]\n",
    "        pipeline = IngestionPipeline(transformations=transformations)\n",
    "\n",
    "        # Create a Document object for LlamaIndex\n",
    "        document = Document(text=combined_text, metadata={})\n",
    "\n",
    "        # Run the ingestion pipeline to extract metadata\n",
    "        nodes = pipeline.run(documents=[document])\n",
    "\n",
    "        # Normalize metadata for each chunk\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Add extracted metadata to each chunk\n",
    "        for doc in docs:\n",
    "            doc.metadata.update(normalize_metadata(nodes[0].metadata))\n",
    "\n",
    "        # Define embeddings\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "        # Create vector database from data\n",
    "        db = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "        # Define retriever\n",
    "        retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "        # Create a chatbot chain\n",
    "        llm_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n",
    "        qa = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm_model,\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            return_generated_question=True,\n",
    "        )\n",
    "        return qa\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    loaded_file = param.String(\"/Users/pradhikshasuresh/Documents/Python/Space.pdf\")\n",
    "    file_type = param.String(\"pdf\")\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.panels = []\n",
    "        self.qa = load_db(self.loaded_file, self.file_type, \"stuff\", 4)\n",
    "\n",
    "    def call_load_db(self, event):\n",
    "        if file_input.value:\n",
    "            with open(\"temp_file\", \"wb\") as f:\n",
    "                f.write(file_input.value)\n",
    "            self.loaded_file = \"temp_file\"\n",
    "            self.file_type = file_input.filename.split('.')[-1]\n",
    "            self.qa = load_db(self.loaded_file, self.file_type, \"stuff\", 4)\n",
    "            self.clr_history()\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            return pn.pane.Markdown(f\"Loaded Default File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.append((query, result[\"answer\"]))\n",
    "        self.answer = result['answer']\n",
    "\n",
    "        self.panels.append(\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "        )\n",
    "        self.panels.append(\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, styles={'background-color': '#F6F6F6'}))\n",
    "        )\n",
    "\n",
    "        inp.value = ''  # clears the input box\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "    def clr_history(self, event=None):\n",
    "        self.chat_history = []\n",
    "        self.panels = []  # Clear the panels as well\n",
    "        return pn.pane.Markdown(\"Chat history cleared.\")\n",
    "\n",
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept='.pdf,.csv,.docx')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_load.on_click(cb.call_load_db)\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput(placeholder='Enter text here…')\n",
    "\n",
    "# Bind the convchain method to the input field\n",
    "conversation = pn.bind(cb.convchain, inp)\n",
    "\n",
    "pn.extension()\n",
    "# Layout including the file input and load button\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    conversation,\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "tab2 = pn.Column(\n",
    "    pn.Row(file_input, button_load),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatBot')),\n",
    "    pn.Tabs(('Conversation', tab1)),\n",
    "    pn.Row(button_clearhistory),\n",
    "    tab2\n",
    ")\n",
    "\n",
    "dashboard.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2464151-1a36-4179-b86a-b3cb9f03db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY SOURCE DOCUMENTS\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "import panel as pn\n",
    "import param\n",
    "import pandas as pd\n",
    "import os\n",
    "import fitz  # PyMuPDF for PDF handling\n",
    "from langdetect import detect  # Library for language detection\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index.core import Document\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.extractors import (\n",
    "    TitleExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    SummaryExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = 'MY_API_KEY'\n",
    "\n",
    "# Helper function to normalize metadata values\n",
    "def normalize_metadata(metadata):\n",
    "    normalized_metadata = {}\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, list):\n",
    "            # Convert lists to strings or other appropriate types\n",
    "            normalized_metadata[key] = ', '.join(map(str, value))\n",
    "        elif isinstance(value, (str, int, float, bool)):\n",
    "            # Keep other types unchanged\n",
    "            normalized_metadata[key] = value\n",
    "        else:\n",
    "            # Handle unexpected types\n",
    "            normalized_metadata[key] = str(value)\n",
    "    return normalized_metadata\n",
    "\n",
    "# Define the helper function to load the database with metadata extraction\n",
    "def load_db(file, file_type, chain_type, k):\n",
    "    try:\n",
    "        # Load documents based on file type\n",
    "        if file_type == 'pdf':\n",
    "            loader = PyPDFLoader(file)\n",
    "            documents = loader.load()\n",
    "        elif file_type == 'csv':\n",
    "            loader = CSVLoader(file_path=file)\n",
    "            documents = loader.load()\n",
    "        elif file_type == 'docx':\n",
    "            loader = Docx2txtLoader(file)\n",
    "            documents = loader.load()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_type}\")\n",
    "\n",
    "        # Combine the text of the documents\n",
    "        combined_text = \" \".join([doc.page_content for doc in documents])\n",
    "\n",
    "        # Initialize LlamaIndex extractors\n",
    "        llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.2, api_key=api_key)\n",
    "        entity_extractor = EntityExtractor(\n",
    "            prediction_threshold=0.5,\n",
    "            label_entities=False,\n",
    "            device=\"cpu\",\n",
    "        )\n",
    "        qa_extractor = QuestionsAnsweredExtractor(questions=3, llm=llm)\n",
    "        summary_extractor = SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm)\n",
    "        title_extractor = TitleExtractor(nodes=5, llm=llm)\n",
    "        keyword_extractor = KeywordExtractor(keywords=10, llm=llm)\n",
    "        node_parser = SentenceSplitter()\n",
    "\n",
    "        transformations = [node_parser, title_extractor, entity_extractor, summary_extractor, qa_extractor, keyword_extractor]\n",
    "        pipeline = IngestionPipeline(transformations=transformations)\n",
    "\n",
    "        # Create a Document object for LlamaIndex\n",
    "        document = Document(text=combined_text, metadata={})\n",
    "\n",
    "        # Run the ingestion pipeline to extract metadata\n",
    "        nodes = pipeline.run(documents=[document])\n",
    "\n",
    "        # Normalize metadata for each chunk\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Add extracted metadata to each chunk\n",
    "        for doc in docs:\n",
    "            doc.metadata.update(normalize_metadata(nodes[0].metadata))\n",
    "\n",
    "        # Define embeddings\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "        # Create vector database from data\n",
    "        db = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "        # Define retriever\n",
    "        retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "        # Create a chatbot chain\n",
    "        llm_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n",
    "        qa = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm_model,\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            return_generated_question=True,\n",
    "        )\n",
    "        return qa\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    loaded_file = param.String(\"/Users/pradhikshasuresh/Documents/Python/Space.pdf\")\n",
    "    file_type = param.String(\"pdf\")\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.panels = []\n",
    "        self.qa = load_db(self.loaded_file, self.file_type, \"stuff\", 4)\n",
    "\n",
    "    def call_load_db(self, event):\n",
    "        if file_input.value:\n",
    "            with open(\"temp_file\", \"wb\") as f:\n",
    "                f.write(file_input.value)\n",
    "            self.loaded_file = \"temp_file\"\n",
    "            self.file_type = file_input.filename.split('.')[-1]\n",
    "            self.qa = load_db(self.loaded_file, self.file_type, \"stuff\", 4)\n",
    "            self.clr_history()\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            return pn.pane.Markdown(f\"Loaded Default File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.append((query, result[\"answer\"]))\n",
    "        self.answer = result['answer']\n",
    "\n",
    "        self.panels.append(\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "        )\n",
    "        self.panels.append(\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, styles={'background-color': '#F6F6F6'}))\n",
    "        )\n",
    "        \n",
    "        # Append source documents to the response\n",
    "        for doc in result[\"source_documents\"]:\n",
    "            self.panels.append(\n",
    "                pn.Row('Source Document:', pn.pane.Markdown(doc.page_content, width=600, styles={'background-color': '#E8E8E8'}))\n",
    "            )\n",
    "\n",
    "        inp.value = ''  # clears the input box\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "    def clr_history(self, event=None):\n",
    "        self.chat_history = []\n",
    "        self.panels = []  # Clear the panels as well\n",
    "        return pn.pane.Markdown(\"Chat history cleared.\")\n",
    "\n",
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept='.pdf,.csv,.docx')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_load.on_click(cb.call_load_db)\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput(placeholder='Enter text here…')\n",
    "\n",
    "# Bind the convchain method to the input field\n",
    "conversation = pn.bind(cb.convchain, inp)\n",
    "\n",
    "pn.extension()\n",
    "# Layout including the file input and load button\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    conversation,\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "tab2 = pn.Column(\n",
    "    pn.Row(file_input, button_load),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatBot')),\n",
    "    pn.Tabs(('Conversation', tab1)),\n",
    "    pn.Row(button_clearhistory),\n",
    "    tab2\n",
    ")\n",
    "\n",
    "dashboard.servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0544c0-b225-48ac-b878-dd4039f0ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY METADATA ALOMG WITH SOURCE DOCUMENT\n",
    "import panel as pn\n",
    "import param\n",
    "import fitz  # PyMuPDF for PDF handling\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index.core import Document\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.extractors import (\n",
    "    TitleExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    SummaryExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = 'MY_API_KEY'\n",
    "\n",
    "\n",
    "# Helper function to normalize metadata values\n",
    "def normalize_metadata(metadata):\n",
    "    normalized_metadata = {}\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, list):\n",
    "            normalized_metadata[key] = ', '.join(map(str, value))\n",
    "        elif isinstance(value, (str, int, float, bool)):\n",
    "            normalized_metadata[key] = value\n",
    "        else:\n",
    "            normalized_metadata[key] = str(value)\n",
    "    return normalized_metadata\n",
    "\n",
    "\n",
    "# Define the helper function to load the database with metadata extraction\n",
    "def load_db(file, file_type, chain_type, k):\n",
    "    try:\n",
    "        if file_type == 'pdf':\n",
    "            loader = PyPDFLoader(file)\n",
    "            documents = loader.load()\n",
    "        elif file_type == 'csv':\n",
    "            loader = CSVLoader(file_path=file)\n",
    "            documents = loader.load()\n",
    "        elif file_type == 'docx':\n",
    "            loader = Docx2txtLoader(file)\n",
    "            documents = loader.load()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_type}\")\n",
    "\n",
    "        combined_text = \" \".join([doc.page_content for doc in documents])\n",
    "\n",
    "        llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.2, api_key=api_key)\n",
    "        entity_extractor = EntityExtractor(prediction_threshold=0.5, label_entities=False, device=\"cpu\")\n",
    "        qa_extractor = QuestionsAnsweredExtractor(questions=3, llm=llm)\n",
    "        summary_extractor = SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm)\n",
    "        title_extractor = TitleExtractor(nodes=5, llm=llm)\n",
    "        keyword_extractor = KeywordExtractor(keywords=10, llm=llm)\n",
    "        node_parser = SentenceSplitter()\n",
    "\n",
    "        transformations = [node_parser, title_extractor, entity_extractor, summary_extractor, qa_extractor, keyword_extractor]\n",
    "        pipeline = IngestionPipeline(transformations=transformations)\n",
    "\n",
    "        document = Document(text=combined_text, metadata={})\n",
    "        nodes = pipeline.run(documents=[document])\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        for doc in docs:\n",
    "            doc.metadata.update(normalize_metadata(nodes[0].metadata))\n",
    "\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "        db = Chroma.from_documents(docs, embeddings)\n",
    "        retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "        llm_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n",
    "        qa = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm_model,\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            return_generated_question=True,\n",
    "        )\n",
    "        return qa\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    loaded_file = param.String(\"/Users/pradhikshasuresh/Documents/Python/Space.pdf\")\n",
    "    file_type = param.String(\"pdf\")\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.panels = []\n",
    "        self.qa = load_db(self.loaded_file, self.file_type, \"stuff\", 4)\n",
    "\n",
    "    def call_load_db(self, event):\n",
    "        if file_input.value:\n",
    "            with open(\"temp_file\", \"wb\") as f:\n",
    "                f.write(file_input.value)\n",
    "            self.loaded_file = \"temp_file\"\n",
    "            self.file_type = file_input.filename.split('.')[-1]\n",
    "            self.qa = load_db(self.loaded_file, self.file_type, \"stuff\", 4)\n",
    "            self.clr_history()\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            return pn.pane.Markdown(f\"Loaded Default File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.append((query, result[\"answer\"]))\n",
    "        self.answer = result['answer']\n",
    "\n",
    "        self.panels.append(\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "        )\n",
    "        self.panels.append(\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, styles={'background-color': '#F6F6F6'}))\n",
    "        )\n",
    "\n",
    "        # Append source documents with metadata to the response\n",
    "        for doc in result[\"source_documents\"]:\n",
    "            metadata_str = \"\\n\".join([f\"{key}: {value}\" for key, value in doc.metadata.items()])\n",
    "            self.panels.append(\n",
    "                pn.Row('Source Document:', pn.pane.Markdown(f\"**Content:**\\n{doc.page_content}\\n\\n**Metadata:**\\n{metadata_str}\", width=600, styles={'background-color': '#E8E8E8'}))\n",
    "            )\n",
    "\n",
    "        inp.value = ''  # clears the input box\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "    def clr_history(self, event=None):\n",
    "        self.chat_history = []\n",
    "        self.panels = []  # Clear the panels as well\n",
    "        return pn.pane.Markdown(\"Chat history cleared.\")\n",
    "\n",
    "\n",
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept='.pdf,.csv,.docx')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_load.on_click(cb.call_load_db)\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput(placeholder='Enter text here…')\n",
    "\n",
    "# Bind the convchain method to the input field\n",
    "conversation = pn.bind(cb.convchain, inp)\n",
    "\n",
    "pn.extension()\n",
    "# Layout including the file input and load button\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    conversation,\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "tab2 = pn.Column(\n",
    "    pn.Row(file_input, button_load),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatBot')),\n",
    "    pn.Tabs(('Conversation', tab1)),\n",
    "    pn.Row(button_clearhistory),\n",
    "    tab2\n",
    ")\n",
    "\n",
    "dashboard.servable()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
